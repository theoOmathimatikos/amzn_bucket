{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T16:13:34.499765Z","iopub.execute_input":"2022-03-28T16:13:34.500425Z","iopub.status.idle":"2022-03-28T16:13:34.505211Z","shell.execute_reply.started":"2022-03-28T16:13:34.500392Z","shell.execute_reply":"2022-03-28T16:13:34.504392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = []\nfor dirname, _, filenames in os.walk('/kaggle/input/amazon-bucket'):\n    for filename in filenames:\n        metadata.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:13:34.802495Z","iopub.execute_input":"2022-03-28T16:13:34.803251Z","iopub.status.idle":"2022-03-28T16:18:26.720231Z","shell.execute_reply.started":"2022-03-28T16:13:34.803214Z","shell.execute_reply":"2022-03-28T16:18:26.719196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imagedata = []\nfor dirname, _, filenames in os.walk('/kaggle/input/amazonimage'):\n    for filename in filenames:\n        imagedata.append(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:18:26.722157Z","iopub.execute_input":"2022-03-28T16:18:26.722482Z","iopub.status.idle":"2022-03-28T16:24:13.081976Z","shell.execute_reply.started":"2022-03-28T16:18:26.72244Z","shell.execute_reply":"2022-03-28T16:24:13.080915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open(metadata[0], \"r\") as f:\n    print(json.load(f))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:13.083249Z","iopub.execute_input":"2022-03-28T16:24:13.08354Z","iopub.status.idle":"2022-03-28T16:24:13.095658Z","shell.execute_reply.started":"2022-03-28T16:24:13.083511Z","shell.execute_reply":"2022-03-28T16:24:13.094463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import skimage\nfrom skimage.io import imread, imshow\nimage = imread(imagedata[0],as_gray = True)\nimshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:13.097754Z","iopub.execute_input":"2022-03-28T16:24:13.098212Z","iopub.status.idle":"2022-03-28T16:24:13.451187Z","shell.execute_reply.started":"2022-03-28T16:24:13.09818Z","shell.execute_reply":"2022-03-28T16:24:13.450538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = []\nim1 = []\nfor meta in metadata:\n    meta = meta.replace(\"/kaggle/input/amazon-bucket/METADATA/\",\"\")\n    meta = meta.replace(\".json\",\"\")\n    m1.append(meta)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:13.452407Z","iopub.execute_input":"2022-03-28T16:24:13.452621Z","iopub.status.idle":"2022-03-28T16:24:13.943219Z","shell.execute_reply.started":"2022-03-28T16:24:13.452596Z","shell.execute_reply":"2022-03-28T16:24:13.942179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img in imagedata:\n    img = img.replace(\"/kaggle/input/amazonimage/IMAGEDATA/\",\"\")\n    img = img.replace(\".jpg\",\"\")\n    im1.append(img)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:13.944878Z","iopub.execute_input":"2022-03-28T16:24:13.945186Z","iopub.status.idle":"2022-03-28T16:24:14.412972Z","shell.execute_reply.started":"2022-03-28T16:24:13.945143Z","shell.execute_reply":"2022-03-28T16:24:14.411992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m11 = set(m1)\nintersect = m11.intersection(im1)\nintersect = list(intersect)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:14.41439Z","iopub.execute_input":"2022-03-28T16:24:14.414728Z","iopub.status.idle":"2022-03-28T16:24:14.849858Z","shell.execute_reply.started":"2022-03-28T16:24:14.414692Z","shell.execute_reply":"2022-03-28T16:24:14.848873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newmetadata = []\nnewimagedata = []\nfor inter in intersect:\n    newmetadata.append(\"/kaggle/input/amazon-bucket/METADATA/\"+inter+\".json\")\n    newimagedata.append(\"/kaggle/input/amazonimage/IMAGEDATA/\"+inter+\".jpg\")","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:14.851291Z","iopub.execute_input":"2022-03-28T16:24:14.851505Z","iopub.status.idle":"2022-03-28T16:24:15.426698Z","shell.execute_reply.started":"2022-03-28T16:24:14.85148Z","shell.execute_reply":"2022-03-28T16:24:15.425691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metafiles = []\nfor i,file in enumerate(newmetadata):\n    if i%25==0:\n        with open(file, \"r\") as f:\n            metafiles.append(json.load(f))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:24:15.427914Z","iopub.execute_input":"2022-03-28T16:24:15.428178Z","iopub.status.idle":"2022-03-28T16:25:19.391172Z","shell.execute_reply.started":"2022-03-28T16:24:15.428149Z","shell.execute_reply":"2022-03-28T16:25:19.390225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantity = []\nkeepos = []\ndef get_total_quantity(metafiles):\n    number = []\n    for i,meta in enumerate(metafiles):\n        if meta['EXPECTED_QUANTITY']<13:\n            number.append(meta['EXPECTED_QUANTITY'])\n            keepos.append(i)\n    return number","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.394154Z","iopub.execute_input":"2022-03-28T16:25:19.394389Z","iopub.status.idle":"2022-03-28T16:25:19.400145Z","shell.execute_reply.started":"2022-03-28T16:25:19.394355Z","shell.execute_reply":"2022-03-28T16:25:19.39956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"quantity = get_total_quantity(metafiles)\nprint(len(quantity))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.401159Z","iopub.execute_input":"2022-03-28T16:25:19.401736Z","iopub.status.idle":"2022-03-28T16:25:19.431923Z","shell.execute_reply.started":"2022-03-28T16:25:19.401706Z","shell.execute_reply":"2022-03-28T16:25:19.43093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nfrom sklearn.datasets import make_classification\nfrom imblearn.under_sampling import CondensedNearestNeighbour\nfrom matplotlib import pyplot\nfrom numpy import where","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.433331Z","iopub.execute_input":"2022-03-28T16:25:19.433649Z","iopub.status.idle":"2022-03-28T16:25:19.446014Z","shell.execute_reply.started":"2022-03-28T16:25:19.433608Z","shell.execute_reply":"2022-03-28T16:25:19.444996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.465644Z","iopub.execute_input":"2022-03-28T16:25:19.465981Z","iopub.status.idle":"2022-03-28T16:25:19.475034Z","shell.execute_reply.started":"2022-03-28T16:25:19.465937Z","shell.execute_reply":"2022-03-28T16:25:19.474081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.51541Z","iopub.execute_input":"2022-03-28T16:25:19.515629Z","iopub.status.idle":"2022-03-28T16:25:19.526019Z","shell.execute_reply.started":"2022-03-28T16:25:19.515603Z","shell.execute_reply":"2022-03-28T16:25:19.525011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.filters import prewitt_h,prewitt_v\nfrom skimage.feature import hog","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.887098Z","iopub.execute_input":"2022-03-28T16:25:19.887576Z","iopub.status.idle":"2022-03-28T16:25:19.897411Z","shell.execute_reply.started":"2022-03-28T16:25:19.887535Z","shell.execute_reply":"2022-03-28T16:25:19.896574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\n \nclass RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Convert an array of RGB images to grayscale\n    \"\"\"\n \n    def __init__(self):\n        pass\n \n    def fit(self, X, y=None):\n        \"\"\"returns itself\"\"\"\n        return self\n \n    def transform(self, X, y=None):\n        \"\"\"perform the transformation and return an array\"\"\"\n        return np.array([skimage.color.rgb2gray(img) for img in X])\n     \nclass HogTransformer(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Expects an array of 2d arrays (1 channel images)\n    Calculates hog features for each img\n    \"\"\"\n \n    def __init__(self, y=None, orientations=9,\n                 pixels_per_cell=(8, 8),\n                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n        self.y = y\n        self.orientations = orientations\n        self.pixels_per_cell = pixels_per_cell\n        self.cells_per_block = cells_per_block\n        self.block_norm = block_norm\n \n    def fit(self, X, y=None):\n        return self\n \n    def transform(self, X, y=None):\n \n        def local_hog(X):\n            return hog(X,\n                       orientations=self.orientations,\n                       pixels_per_cell=self.pixels_per_cell,\n                       cells_per_block=self.cells_per_block,\n                       block_norm=self.block_norm)\n \n        try: # parallel\n            return np.array([local_hog(img) for img in X])\n        except:\n            return np.array([local_hog(img) for img in X])","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.898782Z","iopub.execute_input":"2022-03-28T16:25:19.899255Z","iopub.status.idle":"2022-03-28T16:25:19.914241Z","shell.execute_reply.started":"2022-03-28T16:25:19.899209Z","shell.execute_reply":"2022-03-28T16:25:19.912932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport pickle\nimport bz2\nimport _pickle as cPickle\nimagefiles = []\njj = 0\nfor i,img in enumerate(newimagedata):\n    if i%25==0:\n        if jj in keepos:\n            img1 = Image.open(img).convert(\"RGB\")\n            img1 = img1.resize((180,180),Image.BILINEAR)\n            #150,150\n            img1.save(\"Image1.jpg\")\n            #imagefiles.append(imread(\"Image1.jpg\",as_gray = True))\n            image = imread(\"Image1.jpg\")\n            #edges_prewitt_vertical = prewitt_v(image)\n            imagefiles.append(image)\n        jj = jj+1)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:25:19.915559Z","iopub.execute_input":"2022-03-28T16:25:19.915841Z","iopub.status.idle":"2022-03-28T16:28:24.591066Z","shell.execute_reply.started":"2022-03-28T16:25:19.915786Z","shell.execute_reply":"2022-03-28T16:28:24.590139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimage_train, image_test, quan_train, quan_test = train_test_split(imagefiles, quantity, test_size=0.25, random_state=42,stratify=quantity)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:28:25.036556Z","iopub.execute_input":"2022-03-28T16:28:25.037681Z","iopub.status.idle":"2022-03-28T16:28:25.115291Z","shell.execute_reply.started":"2022-03-28T16:28:25.037641Z","shell.execute_reply":"2022-03-28T16:28:25.114346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, Normalizer\nimport skimage\n \n# create an instance of each transformer\ngrayify = RGB2GrayTransformer()\nhogify = HogTransformer(\n    pixels_per_cell=(14, 14), \n    cells_per_block=(2,2), \n    orientations=9, \n    block_norm='L2-Hys'\n)\nscalify = StandardScaler()\n \n# call fit_transform on each transform converting X_train step by step\nX_train_gray = grayify.fit_transform(image_train)\nX_train_hog = hogify.fit_transform(X_train_gray)\nX_train_prepared = scalify.fit_transform(X_train_hog)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:28:25.369716Z","iopub.execute_input":"2022-03-28T16:28:25.370118Z","iopub.status.idle":"2022-03-28T16:30:09.259957Z","shell.execute_reply.started":"2022-03-28T16:28:25.370085Z","shell.execute_reply":"2022-03-28T16:30:09.259056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:09.261171Z","iopub.execute_input":"2022-03-28T16:30:09.26144Z","iopub.status.idle":"2022-03-28T16:30:09.26602Z","shell.execute_reply.started":"2022-03-28T16:30:09.261412Z","shell.execute_reply":"2022-03-28T16:30:09.265143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score,confusion_matrix,ConfusionMatrixDisplay","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:09.267667Z","iopub.execute_input":"2022-03-28T16:30:09.268047Z","iopub.status.idle":"2022-03-28T16:30:09.276508Z","shell.execute_reply.started":"2022-03-28T16:30:09.268005Z","shell.execute_reply":"2022-03-28T16:30:09.27586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:09.277752Z","iopub.execute_input":"2022-03-28T16:30:09.278003Z","iopub.status.idle":"2022-03-28T16:30:09.287202Z","shell.execute_reply.started":"2022-03-28T16:30:09.277977Z","shell.execute_reply":"2022-03-28T16:30:09.286348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_gray = grayify.transform(image_test)\nX_test_hog = hogify.transform(X_test_gray)\nX_test_prepared = scalify.transform(X_test_hog)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:09.288472Z","iopub.execute_input":"2022-03-28T16:30:09.288742Z","iopub.status.idle":"2022-03-28T16:30:41.961523Z","shell.execute_reply.started":"2022-03-28T16:30:09.288712Z","shell.execute_reply":"2022-03-28T16:30:41.960483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loosen_error(predictions, real_values, thresh = 0):\n    \"\"\"A loosen error definition. If the model predicts a near value (the difference of the prediction and real label\n    is at most 1), then a credit is given to the model. \"\"\"\n    correct = 0\n    somewhat_correct = 0\n    total = 0\n    for i in range(len(real_values)):\n        total += 1\n        if real_values[i] >= 2 or predictions[i] >= 2: \n            if real_values[i] - predictions[i] == 0:\n                correct += 1\n                somewhat_correct += 1\n            if abs(real_values[i] - predictions[i]) <= 1:\n                if thresh == 0:\n                    somewhat_correct += 1 - 1/real_values[i]\n                else:\n                    somewhat_correct += thresh\n    return somewhat_correct/total, correct/total","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:41.962886Z","iopub.execute_input":"2022-03-28T16:30:41.963386Z","iopub.status.idle":"2022-03-28T16:30:41.970289Z","shell.execute_reply.started":"2022-03-28T16:30:41.963355Z","shell.execute_reply":"2022-03-28T16:30:41.969673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC,LinearSVC\nfrom sklearn.linear_model import RidgeClassifier,LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.neural_network import MLPClassifier\n#gnb = RandomForestClassifier(n_estimators=500)\ngnb = SGDClassifier(random_state=42, max_iter=2000, tol=1e-3)\ngnb.fit(X_train_prepared,quan_train)\npredictions = gnb.predict(X_test_prepared)\nprint(f1_score(quan_test,predictions,average='macro'))\nfig,ax = plt.subplots(figsize=(20, 10))\ncm = confusion_matrix(quan_test,predictions,labels=np.unique(quantity))\ndisp = ConfusionMatrixDisplay(cm, display_labels=np.unique(quantity))\ndisp.plot(ax=ax)\nplt.show()\nprint(gnb.score(X_test_prepared, quan_test))\nprint(loosen_error(predictions,quan_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:30:41.971168Z","iopub.execute_input":"2022-03-28T16:30:41.971626Z","iopub.status.idle":"2022-03-28T16:36:59.688314Z","shell.execute_reply.started":"2022-03-28T16:30:41.971594Z","shell.execute_reply":"2022-03-28T16:36:59.687124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gnb = RandomForestClassifier(n_estimators=500)\ngnb.fit(X_train_prepared,quan_train)\npredictions = gnb.predict(X_test_prepared)\nprint(f1_score(quan_test,predictions,average='macro'))\nfig,ax = plt.subplots(figsize=(20, 10))\ncm = confusion_matrix(quan_test,predictions,labels=np.unique(quantity))\ndisp = ConfusionMatrixDisplay(cm, display_labels=np.unique(quantity))\ndisp.plot(ax=ax)\nplt.show()\nprint(gnb.score(X_test_prepared, quan_test))\nprint(loosen_error(predictions,quan_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:44:40.513052Z","iopub.execute_input":"2022-03-28T16:44:40.513413Z","iopub.status.idle":"2022-03-28T16:53:07.668998Z","shell.execute_reply.started":"2022-03-28T16:44:40.513368Z","shell.execute_reply":"2022-03-28T16:53:07.66811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gnb = MLPClassifier(solver='sgd',max_iter=2000)\ngnb.fit(X_train_prepared,quan_train)\npredictions = gnb.predict(X_test_prepared)\nprint(f1_score(quan_test,predictions,average='macro'))\nfig,ax = plt.subplots(figsize=(20, 10))\ncm = confusion_matrix(quan_test,predictions,labels=np.unique(quantity))\ndisp = ConfusionMatrixDisplay(cm, display_labels=np.unique(quantity))\ndisp.plot(ax=ax)\nplt.show()\nprint(gnb.score(X_test_prepared, quan_test))\nprint(loosen_error(predictions,quan_test))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T16:53:07.671165Z","iopub.execute_input":"2022-03-28T16:53:07.671495Z","iopub.status.idle":"2022-03-28T16:59:01.106328Z","shell.execute_reply.started":"2022-03-28T16:53:07.671452Z","shell.execute_reply":"2022-03-28T16:59:01.105395Z"},"trusted":true},"execution_count":null,"outputs":[]}]}