{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-28T20:19:41.161655Z","iopub.execute_input":"2022-03-28T20:19:41.162277Z","iopub.status.idle":"2022-03-28T20:19:41.192243Z","shell.execute_reply.started":"2022-03-28T20:19:41.162173Z","shell.execute_reply":"2022-03-28T20:19:41.191578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir\nimport os.path\nimport numpy as np\nimport random\nimport json\n\nimg_dir= \"/kaggle/input/amazonimage/IMAGEDATA/\"\nmeta_dir = \"/kaggle/input/amazon-bucket/METADATA/\"\n\n# getting whole metadata list \ndef get_metadata(img_dir,meta_dir):\n    metadata=[]\n    n_images=0\n#    img_list = listdir(img_dir)\n#    N = len(img_list)\n    N = 535234\n    for i in range(N):\n        if i%1000 == 0:\n            print(\"get_metadata: processing (%d/%d)...\" % (i,N))\n        jpg_path = '%s%05d.jpg' % (img_dir,i+1)\n        json_path = '%s%05d.json' % (meta_dir,i+1)\n        if os.path.isfile(jpg_path) and os.path.isfile(json_path):\n            d = json.loads(open(json_path).read())\n            metadata.append(d)\n            n_images = n_images + 1\n        else:\n            metadata.append({})\n    print(\"get_metadata: Available Images: %d\" % n_images)\n    return metadata,n_images\n\n# getting instance list\ndef get_instance_data(metadata):\n    instances={}\n    N = len(metadata)\n    for i in range(N):\n        if i%1000 == 0:\n            print(\"get_instance_data: processing (%d/%d)...\" % (i,N))\n        if metadata[i]:\n            quantity = metadata[i]['EXPECTED_QUANTITY']\n            if quantity>0:\n                bin_info = metadata[i]['BIN_FCSKU_DATA']\n                bin_keys = list(bin_info.keys())\n                for j in range(0,len(bin_info)):\n                    instance_info = bin_info[bin_keys[j]]\n                    asin = instance_info['asin']\n                    if asin in instances:\n                        # occurance\n                        instances[asin]['repeat'] = instances[asin]['repeat'] + 1\n                        # quantity\n                        instances[asin]['quantity'] = instances[asin]['quantity'] + instance_info['quantity']\n                        instances[asin]['bin_list'].append(i)\n                    else:\n                        instances[asin]={}\n                        instances[asin]['repeat'] = 1\n                        instances[asin]['quantity'] = instance_info['quantity']\n                        instances[asin]['name'] = instance_info['name']\n                        bin_list = []\n                        bin_list.append(i)\n                        instances[asin]['bin_list'] = bin_list\n    return instances\n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:19:41.348115Z","iopub.execute_input":"2022-03-28T20:19:41.34845Z","iopub.status.idle":"2022-03-28T20:19:41.362155Z","shell.execute_reply.started":"2022-03-28T20:19:41.348415Z","shell.execute_reply":"2022-03-28T20:19:41.361236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata,n_images = get_metadata(img_dir, meta_dir)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T20:19:41.465311Z","iopub.execute_input":"2022-03-28T20:19:41.46576Z","iopub.status.idle":"2022-03-28T21:42:36.321425Z","shell.execute_reply.started":"2022-03-28T20:19:41.465724Z","shell.execute_reply":"2022-03-28T21:42:36.320533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(metadata))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:42:36.324329Z","iopub.execute_input":"2022-03-28T21:42:36.32481Z","iopub.status.idle":"2022-03-28T21:42:36.331395Z","shell.execute_reply.started":"2022-03-28T21:42:36.324744Z","shell.execute_reply":"2022-03-28T21:42:36.330078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"instances = get_instance_data(metadata)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:42:36.333396Z","iopub.execute_input":"2022-03-28T21:42:36.334036Z","iopub.status.idle":"2022-03-28T21:42:43.063287Z","shell.execute_reply.started":"2022-03-28T21:42:36.333972Z","shell.execute_reply":"2022-03-28T21:42:43.062587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"dumping metadata.json...\")\nwith open('metadata.json','w') as fp:\n    json.dump(metadata,fp)\nprint(\"dumping instances.json...\")\nwith open('instances.json','w') as fp:\n    json.dump(instances,fp)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:42:43.065406Z","iopub.execute_input":"2022-03-28T21:42:43.065653Z","iopub.status.idle":"2022-03-28T21:44:03.882655Z","shell.execute_reply.started":"2022-03-28T21:42:43.065618Z","shell.execute_reply":"2022-03-28T21:44:03.881945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os import listdir\nimport os.path\nimport numpy as np\nimport random\n\nimg_dir= \"/kaggle/input/amazonimage/IMAGEDATA/\"\nmeta_dir = \"/kaggle/input/amazon-bucket/METADATA\"\n\n#img_list = listdir(img_dir)\n#N = len(img_list)\nN = 535234\nlist_random = list(range(N))\nrandom.shuffle(list_random)\n\n# finding images that metadata exists\nmeta_avail = np.zeros(N, dtype=bool)\nfor i in range(N):\n    meta_fname = os.path.join(meta_dir,('%05d.json'%(i+1)))\n    if os.path.isfile(meta_fname):\n        meta_avail[i] = True\n\n# assign validataion set\nvalset = np.zeros(N, dtype=bool)\nn_valset = int(round(N*0.1))\ncount = 0\nrandom.shuffle(list_random)\nfor i in range(N):\n    idx = list_random[i]\n    if meta_avail[idx]:\n        valset[idx]=True\n        count = count + 1\n        if count == n_valset:\n            break","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:44:03.883871Z","iopub.execute_input":"2022-03-28T21:44:03.88412Z","iopub.status.idle":"2022-03-28T21:55:08.400765Z","shell.execute_reply.started":"2022-03-28T21:44:03.884087Z","shell.execute_reply":"2022-03-28T21:55:08.400014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_f = open('random_train.txt','w')\nval_f = open('random_val.txt','w')\nfor i in range(N):\n    if meta_avail[i]:\n        if valset[i]:\n            val_f.write(\"%d\\n\" % (i+1))\n        else:\n            train_f.write(\"%d\\n\" % (i+1))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:08.40203Z","iopub.execute_input":"2022-03-28T21:55:08.404024Z","iopub.status.idle":"2022-03-28T21:55:08.773049Z","shell.execute_reply.started":"2022-03-28T21:55:08.403991Z","shell.execute_reply":"2022-03-28T21:55:08.772311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport unicodedata\nimport numpy as np\nimport json\nimport random\n\n# loading metaata\nrandom_train = \"random_train.txt\"\nrandom_val = \"random_val.txt\"\nmetadata_file = \"metadata.json\"\n\nhard = False\n\ndef get_quantity(idx):\n    quantity = 0\n    if metadata[idx]:\n        quantity = metadata[idx]['EXPECTED_QUANTITY']\n    return quantity\n\ndef get_moderate_list(split_file):\n    print(\"loading random split file\")\n    train_list = []\n    with open(split_file) as f:\n        for line in f.readlines():\n            idx = int(line)-1\n            quantity = get_quantity(idx)\n            if hard:\n                train_list.append([idx,quantity])\n            else:\n                if quantity < 6:\n                    train_list.append([idx,quantity])\n    return train_list \n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:08.77446Z","iopub.execute_input":"2022-03-28T21:55:08.774719Z","iopub.status.idle":"2022-03-28T21:55:08.79496Z","shell.execute_reply.started":"2022-03-28T21:55:08.774684Z","shell.execute_reply":"2022-03-28T21:55:08.794272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"loading metadata!\")\nwith open(metadata_file) as json_file:\n    metadata = json.load(json_file)\nN = len(metadata)\n\ntrain_list = get_moderate_list(random_train)\nval_list = get_moderate_list(random_val)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:08.796227Z","iopub.execute_input":"2022-03-28T21:55:08.796605Z","iopub.status.idle":"2022-03-28T21:55:28.45143Z","shell.execute_reply.started":"2022-03-28T21:55:08.796569Z","shell.execute_reply":"2022-03-28T21:55:28.450664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"dumping train and val sets into json file\")\nif hard:\n    out_fname = 'counting_train_hard.json'\nelse:\n    out_fname = 'counting_train.json'\nwith open(out_fname,'w') as f:\n    json.dump(train_list,f)\n\nif hard:\n    out_fname = 'counting_val_hard.json'\nelse:\n    out_fname = 'counting_val.json'\nwith open(out_fname,'w') as f:\n    json.dump(val_list,f)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:28.452773Z","iopub.execute_input":"2022-03-28T21:55:28.453988Z","iopub.status.idle":"2022-03-28T21:55:29.774961Z","shell.execute_reply.started":"2022-03-28T21:55:28.453946Z","shell.execute_reply":"2022-03-28T21:55:29.774222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:29.77752Z","iopub.execute_input":"2022-03-28T21:55:29.77771Z","iopub.status.idle":"2022-03-28T21:55:29.786019Z","shell.execute_reply.started":"2022-03-28T21:55:29.777686Z","shell.execute_reply":"2022-03-28T21:55:29.785137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.utils.data as data\nimport torch\n#return img.resize((200,200),Image.BILINEAR)\n#        if os.path.exists(os.path.join(self.root, img_path))==False:\n#            img_path = \"237454.jpg\"\nfrom PIL import Image\nimport numpy as np\nimport os\nimport os.path\nimport json\n\ndef default_loader(path):\n    img = Image.open(path).convert('RGB')\n    return img.resize((200,200),Image.BILINEAR)\n\nclass ImageFolderCounting(data.Dataset):\n    def __init__(self, root, list_file, transform=None, target_transform=None,\n                 loader=default_loader):\n        print('loading data_list json file...')\n        with open(list_file) as f:\n            data_list = json.loads(f.read())\n        print('finished loading data_list json file')\n        self.root = root\n        self.transform = transform\n        self.target_transform = target_transform\n        self.loader = loader\n        self.data_list = data_list\n        self.N = len(self.data_list)\n    \n    def __getitem__(self, index):\n        # pick up the image\n        item = self.data_list[index]\n        target = int(item[1])\n        img_path = '%05d.jpg' % (item[0]+1)\n        if os.path.exists(os.path.join(self.root, img_path))==False:\n            img_path = \"237454.jpg\"\n        img = self.loader(os.path.join(self.root, img_path))\n        if self.transform is not None:\n            img = self.transform(img)\n        if self.target_transform is not None:\n            target = self.target_transform(target)\n        return img, target\n    \n    def __len__(self):\n        return self.N","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:29.787524Z","iopub.execute_input":"2022-03-28T21:55:29.78778Z","iopub.status.idle":"2022-03-28T21:55:31.173342Z","shell.execute_reply.started":"2022-03-28T21:55:29.787746Z","shell.execute_reply":"2022-03-28T21:55:31.172608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport shutil\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim\nimport torch.utils.data\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\nimport torchvision.models as models\n\nimport numpy as np\nfrom PIL import Image\n\nmodel_names = sorted(name for name in models.__dict__\n    if name.islower() and not name.startswith(\"__\")\n    and callable(models.__dict__[name]))\n\n\nparser = argparse.ArgumentParser(description='PyTorch ABID Counting')\nparser.add_argument('data', metavar='DIR', help='path to dataset')\nparser.add_argument('--arch', '-a', metavar='ARCH', default='resnet34', choices=model_names, help='model architecture: ' + ' | '.join(model_names) + ' (default: resnet34)')\nparser.add_argument('-j', '--workers', default=4, type=int, metavar='N', help='number of data loading workers (default: 4)')\nparser.add_argument('--epochs', default=10, type=int, metavar='N', help='number of total epochs to run')\nparser.add_argument('--start-epoch', default=0, type=int, metavar='N', help='manual epoch number (useful on restarts)')\nparser.add_argument('-b', '--batch_size', default=128, type=int, metavar='N', help='mini-batch size (default: 256)')\nparser.add_argument('--lr', '--learning-rate', default=0.1, type=float, metavar='LR', help='initial learning rate')\nparser.add_argument('--lrd','--learning-rate-decay-step', default=10, type=int, metavar='N', help='learning rate decay epoch')\nparser.add_argument('--momentum', default=0.9, type=float, metavar='M', help='momentum')\nparser.add_argument('--weight-decay', '--wd', default=1e-4, type=float, metavar='W', help='weight decay (default: 1e-4)')\nparser.add_argument('--print-freq', '-p', default=10, type=int, metavar='N', help='print frequency (default: 10)')\nparser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\nparser.add_argument('--evaluate', default=False, type=bool, metavar='BOOL', help='evaluate or train')\n\ndef show_image(im,target):\n    print('count: %d' % target[0])\n    npimg = np.transpose(im[0].mul(255).byte().numpy(), (1,2,0))\n    img_batch = npimg\n    for idx in range(5):\n        print('count : %d' % target[idx+1])\n        npimg = np.transpose(im[idx+1].mul(255).byte().numpy(), (1,2,0))\n        img_batch = np.concatenate((img_batch,npimg), axis=0)\n    img_pair_disp = Image.fromarray(img_batch)\n    img_pair_disp.show()\n\nbest_prec = 0\ntrain_loss_list = []\nval_acc_list= []\n\ndef main():\n    global args, best_prec, train_loss_list, val_acc_list\n    #args = parser.parse_args(args=[])\n    args, unknown = parser.parse_known_args()\n    # create model\n    print(\"=> creating model '{}'\".format(args.arch))\n    net = models.__dict__[args.arch]()\n\n    in_features = net.fc.in_features\n    new_fc = nn.Linear(in_features,6)\n    net.fc = new_fc\n\n    #net.cuda()\n\n    # optionally resume from a checkpoint\n    if args.resume:\n        if os.path.isfile(args.resume):\n            print(\"=> loading checkpoint '{}'\".format(args.resume))\n            checkpoint = torch.load(args.resume)\n            net.load_state_dict(checkpoint['state_dict'])\n            args.start_epoch = checkpoint['epoch']\n            best_prec = checkpoint['best_prec']\n            train_loss_list = checkpoint['train_loss_list']\n            val_acc_list = checkpoint['val_acc_list']\n        else:\n            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    \n    net.to(DEVICE)\n    params = net.parameters()\n    snapshot_fname = \"snapshots/%s.pth.tar\" % args.arch\n    snapshot_best_fname = \"snapshots/%s_best.pth.tar\" % args.arch\n\n    cudnn.benchmark = True\n\n    # Data loading code\n    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n\n    train_loader = torch.utils.data.DataLoader(\n        ImageFolderCounting(\"/kaggle/input/amazonimage/IMAGEDATA/\", 'counting_train.json', transforms.Compose([\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=True,\n        num_workers=args.workers, pin_memory=True)\n\n    val_loader = torch.utils.data.DataLoader(\n        ImageFolderCounting(\"/kaggle/input/amazonimage/IMAGEDATA/\", 'counting_val.json', transforms.Compose([\n            transforms.ToTensor(),\n            normalize,\n        ])),\n        batch_size=args.batch_size, shuffle=False,\n        num_workers=args.workers, pin_memory=True)\n\n    # define loss function (criterion) and pptimizer\n    criterion = nn.CrossEntropyLoss().cuda()\n\n    optimizer = torch.optim.SGD(params, args.lr,\n                                momentum=args.momentum,\n                                weight_decay=args.weight_decay)\n\n    # evaluate on validation set\n    if args.evaluate == True:\n        validate(val_loader, net, criterion, True)\n        return\n    \n    for epoch in range(args.start_epoch, args.epochs):\n        # train for one epoch\n\n        train(train_loader, net, criterion, optimizer, epoch)\n        # evaluate on validation set\n        prec = validate(val_loader, net, criterion, True)\n\n        # remember best prec@1 and save checkpoint\n        is_best = prec > best_prec\n        best_prec = max(prec, best_prec)\n    return net\n    \n\ndef train(train_loader, net, criterion, optimizer, epoch):\n    cur_lr = adjust_learning_rate(optimizer, epoch)\n\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    train_acc = AverageMeter()\n\n    # switch to train mode\n    net.train()\n\n    end = time.time()\n\n    for i, (input, target) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        target = target.cuda()\n        input = input.cuda()\n        input_var = torch.autograd.Variable(input)\n        target_var = torch.autograd.Variable(target)\n\n        # compute output\n        output = net(input_var)\n        loss = criterion(output, target_var)\n\n        # measure accuracy and record loss\n        score,idx = torch.max(output.data,1)\n        correct = (target==idx)\n        acc = float(correct.sum())/input.size(0)\n\n        losses.update(loss.data, input.size(0))\n        train_acc.update(acc, input.size(0))\n\n        # compute gradient and do SGD step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if i%100==0:\n            print('Epoch: [{0}][{1}/{2}] lr {cur_lr:.5f}\\t'\n                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                  'Prec {train_acc.val:.3f} ({train_acc.avg:.3f})'.format(\n                   epoch, i, len(train_loader), cur_lr=cur_lr, batch_time=batch_time,\n                   data_time=data_time, loss=losses, train_acc=train_acc))\n        #train_loss_list.append(losses.val)\n\ndef validate(val_loader, net, criterion, file_out):\n    batch_time = AverageMeter()\n    losses = AverageMeter()\n    val_acc = AverageMeter()\n\n    # switch to evaluate mode\n    net.eval()\n    \n    if file_out==True:\n        f = open('counting_result.txt','w') \n\n    end = time.time()\n    with torch.no_grad():\n        for i, (input, target) in enumerate(val_loader):\n            target = target.cuda()\n            input = input.cuda()\n            input_var = torch.autograd.Variable(input, volatile=True)\n            target_var = torch.autograd.Variable(target, volatile=True)\n\n            # compute output\n            output = net(input_var)\n            loss = criterion(output, target_var)\n\n            # measure accuracy and record loss\n            score,idx = torch.max(output.data,1)\n            correct = (target==idx)\n            acc = float(correct.sum())/input.size(0)\n \n            if file_out==True:\n                for j in range(input.size(0)):\n                    f.write('%d\\n' % idx[j].item())\n\n            # measure accuracy and record loss\n            losses.update(loss.data, input.size(0))\n            val_acc.update(acc, input.size(0))\n\n            # measure elapsed time\n            batch_time.update(time.time() - end)\n            end = time.time()\n            if i%100==0:\n                print('Test: [{0}/{1}]\\t'\n                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n                      'Prec {val_acc.val:.3f} ({val_acc.avg:.3f})'.format(\n                       i, len(val_loader), batch_time=batch_time, loss=losses,\n                       val_acc=val_acc))\n\n    print(' * Prec {val_acc.avg:.3f}'.format(val_acc=val_acc))\n    if file_out==True:\n        f.close()\n\n    val_acc_list.append(val_acc.avg)\n    return val_acc.avg\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef adjust_learning_rate(optimizer, epoch):\n    \"\"\"Sets the learning rate to the initial LR decayed by 1/10 every args.lrd epochs\"\"\"\n    lr = args.lr * (0.1 ** (epoch // args.lrd))\n    for param_group in optimizer.param_groups:\n        param_group['lr'] = lr\n    return lr\n","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:31.175701Z","iopub.execute_input":"2022-03-28T21:55:31.1761Z","iopub.status.idle":"2022-03-28T21:55:31.40785Z","shell.execute_reply.started":"2022-03-28T21:55:31.176062Z","shell.execute_reply":"2022-03-28T21:55:31.407142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = main()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:55:31.408994Z","iopub.execute_input":"2022-03-28T21:55:31.409298Z","iopub.status.idle":"2022-03-29T04:02:37.998407Z","shell.execute_reply.started":"2022-03-28T21:55:31.409261Z","shell.execute_reply":"2022-03-29T04:02:37.996907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nimport numpy as np\n\nwith open('/kaggle/working/counting_val.json') as f:        \n    val_list = json.loads(f.read())\n\nn = 0\nperclass_correct = np.zeros(6) \nperclass_dist = np.zeros(6) \nperclass_N = np.zeros(6)\n\nconfusionmatrix = np.zeros((6,6))\nwith open('counting_result.txt') as f:\n    for line in f:\n        pred = int(line)\n        gt = int(val_list[n][1])\n        perclass_correct[gt] = perclass_correct[gt] + int(pred==gt) \n        perclass_dist[gt] = perclass_dist[gt] + np.power(pred-gt,2)\n        perclass_N[gt] = perclass_N[gt] + 1\n        n = n+1\n        confusionmatrix[gt][pred] = confusionmatrix[gt][pred]+1\n\nprint('accuracy')\nprint('%d/%d (%f)' %(perclass_correct.sum(), perclass_N.sum(), perclass_correct.sum()/perclass_N.sum()))\nprint('RMSE(Root mean squared error)')\nprint(np.sqrt(perclass_dist.sum()/perclass_N.sum()))\nprint('Per class accuracy')\nprint(perclass_correct/perclass_N)\nprint('Per class RMSE')\nprint(np.sqrt(perclass_dist/perclass_N))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T04:02:38.324005Z","iopub.execute_input":"2022-03-29T04:02:38.324445Z","iopub.status.idle":"2022-03-29T04:02:38.607783Z","shell.execute_reply.started":"2022-03-29T04:02:38.324407Z","shell.execute_reply":"2022-03-29T04:02:38.607056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(confusionmatrix)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T04:02:38.609185Z","iopub.execute_input":"2022-03-29T04:02:38.609465Z","iopub.status.idle":"2022-03-29T04:02:38.614636Z","shell.execute_reply.started":"2022-03-29T04:02:38.609428Z","shell.execute_reply":"2022-03-29T04:02:38.613646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(perclass_correct,perclass_N)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T04:02:38.616158Z","iopub.execute_input":"2022-03-29T04:02:38.616594Z","iopub.status.idle":"2022-03-29T04:02:38.625902Z","shell.execute_reply.started":"2022-03-29T04:02:38.616556Z","shell.execute_reply":"2022-03-29T04:02:38.625014Z"},"trusted":true},"execution_count":null,"outputs":[]}]}